# Gu√≠a de Celery Tasks Simplificado

## Arquitectura Refactorizada

Este proyecto ahora usa un sistema **simplificado** de Celery tasks basado en el `service_locator`, eliminando la complejidad del sistema anterior de m√∫ltiples instancias de Celery.

---

## Cambios Principales

### ANTES (Sistema Complejo)

```python
# Cada m√≥dulo ten√≠a su propia instancia de Celery
from celery import Celery
from core.config.settings import env

app = Celery("invoicing", broker=env.RABBITMQ_URL, backend=env.REDIS_URL)

@app.task
def emit_invoice():
    return "Done"
```

**Problemas:**
- M√∫ltiples instancias de Celery
- Discovery complejo que buscaba instancias
- Merge manual de tasks
- Configuraci√≥n duplicada

### AHORA (Sistema Simplificado)

```python
# Tasks son funciones Python normales
def emit_invoice():
    """Task para emitir factura"""
    return "Done"
```

**Ventajas:**
- Una sola instancia de Celery
- Tasks son funciones normales
- Discovery autom√°tico desde service_locator
- Configuraci√≥n centralizada
- F√°cil testing

---

## C√≥mo Funciona

### 1. Definir Tasks (Input Adapter)

Las tasks se definen como **funciones Python normales** en cada m√≥dulo:

**Ubicaci√≥n:** `modules/{module}/adapter/input/tasks/`

```python
# modules/invoicing/adapter/input/tasks/invoice.py
"""
Tasks del m√≥dulo Invoicing - Input Adapter.
"""

def emit_invoice():
    """
    Task para emitir factura.

    Ser√° registrada autom√°ticamente como: "invoicing.emit_invoice"
    """
    import time
    time.sleep(10)
    return "Factura emitida!"

def process_refund(invoice_id: int):
    """Task para procesar reembolso"""
    return f"Reembolso procesado para invoice {invoice_id}"
```

### 2. Registrar Tasks en module.py

Las tasks se registran en el `service_locator` a trav√©s del `module.py`:

```python
# modules/invoicing/module.py
from shared.interfaces.module_registry import ModuleInterface
from typing import Dict

class InvoicingModule(ModuleInterface):

    @property
    def service(self) -> Dict[str, object]:
        # Importar las tasks como funciones normales
        from .adapter.input.tasks import invoice

        return {
            "purchase_invoice_service": self._container.purchase_invoice_service,
            # Exponer las tasks como un dict de callables
            "invoicing_tasks": {
                "emit_invoice": invoice.emit_invoice,
            },
        }
```

**Convenci√≥n de nombres:**
- El servicio debe terminar en `_tasks`
- Formato: `{module_name}_tasks`
- Ejemplos: `invoicing_tasks`, `yiqi_erp_tasks`, `notifications_tasks`

### 3. Discovery Autom√°tico

El sistema descubre autom√°ticamente todas las tasks desde el `service_locator`:

```python
# core/celery/discovery.py
from celery import Celery
from core.config.settings import env

def create_celery_worker() -> Celery:
    """Crea el worker de Celery con todas las tasks descubiertas"""
    from shared.interfaces.service_locator import service_locator

    # Crear una √∫nica instancia de Celery
    app = Celery("hexa_worker", broker=env.RABBITMQ_URL, backend=env.REDIS_URL)

    # Obtener todos los servicios que terminan en "_tasks"
    task_services = {
        name: service
        for name, service in service_locator._services.items()
        if name.endswith("_tasks")
    }

    # Registrar cada funci√≥n como task de Celery
    for service_name, task_dict in task_services.items():
        module_name = service_name.replace("_tasks", "")

        for task_name, task_func in task_dict.items():
            # Registrar con nombre: "invoicing.emit_invoice"
            full_task_name = f"{module_name}.{task_name}"
            app.task(name=full_task_name)(task_func)
            print(f"  ‚úì Registered: {full_task_name}")

    return app
```

### 4. Iniciar el Worker

```bash
# Comando simplificado
uv run hexa celery-apps
```

```python
# hexa/__main__.py
@cmd.command("celery-apps")
def run_celery():
    """Inicia el worker de Celery con todas las tasks descubiertas"""
    from core.celery.discovery import create_celery_worker

    app = create_celery_worker()
    app.worker_main(["worker", "--loglevel=INFO"])
```

**Output esperado:**
```
üì¶ Discovered 3 task services from service_locator
  ‚úì Registered: invoicing.emit_invoice
  ‚úì Registered: yiqi_erp.emit_invoice
  ‚úì Registered: notifications.send_notification

‚úÖ Total 3 tasks registered in Celery worker
```

---

## Uso de Tasks

### Desde Endpoints (API)

```python
# modules/invoicing/adapter/input/api/v1/purchase_invoice.py
from shared.interfaces.service_locator import service_locator

@purchase_invoice_router.post("")
async def create_purchase_invoice(
    purchase_invoice: CreatePurchaseInvoiceRequest,
    emit_to_yiqi: bool,
):
    invoice = await service.create(purchase_invoice)
    invoice_saved = await service.save(invoice)

    # Ejecutar task de Celery de forma as√≠ncrona
    if emit_to_yiqi:
        yiqi_tasks = service_locator.get_service("yiqi_erp_tasks")
        yiqi_tasks["emit_invoice"].delay(invoice_saved.model_dump())

    return invoice_saved
```

### Desde Otros M√≥dulos

```python
# modules/accounting/application/service/accounting.py
from shared.interfaces.service_locator import service_locator

class AccountingService:

    async def process_invoice(self, invoice_id: int):
        # Obtener tasks de invoicing
        invoicing_tasks = service_locator.get_service("invoicing_tasks")

        # Ejecutar task de forma as√≠ncrona
        invoicing_tasks["emit_invoice"].delay()

        # O con apply_async para m√°s opciones
        invoicing_tasks["emit_invoice"].apply_async(
            countdown=60,  # Ejecutar en 60 segundos
            retry=True,
        )
```

### Testing de Tasks

```python
# tests/test_invoicing_tasks.py
from modules.invoicing.adapter.input.tasks.invoice import emit_invoice

def test_emit_invoice():
    # Las tasks son funciones normales, f√°ciles de testear
    result = emit_invoice()
    assert result == "Factura emitida!"
```

---

## Type Safety con Protocols

Para tener **autocompletado** y **type checking**, se crearon protocols en `shared/interfaces/service_protocols.py`:

```python
# shared/interfaces/service_protocols.py

class InvoicingTasksProtocol(Protocol):
    """API p√∫blica de tasks de Celery del m√≥dulo Invoicing"""

    def emit_invoice(self) -> str:
        """
        Task para emitir factura.

        Usage:
            tasks = service_locator.get_service("invoicing_tasks")
            tasks["emit_invoice"].delay()
        """
        ...

class YiqiERPTasksProtocol(Protocol):
    """API p√∫blica de tasks de Celery del m√≥dulo YiqiERP"""

    def emit_invoice(self, data: Any) -> str:
        """Task para emitir factura al ERP externo"""
        ...
```

**Uso con type hints:**

```python
from shared.interfaces.service_protocols import InvoicingTasksProtocol
from shared.interfaces.service_locator import service_locator

# Con type hint
tasks: InvoicingTasksProtocol = service_locator.get_service("invoicing_tasks")
tasks["emit_invoice"].delay()  # Autocompletado funciona!
```

---

## Agregar Nueva Task

### Paso 1: Crear la funci√≥n

```python
# modules/accounting/adapter/input/tasks/accounting.py
"""Tasks del m√≥dulo Accounting"""

def generate_report(start_date: str, end_date: str):
    """
    Task para generar reporte contable.

    Ser√° registrada como: "accounting.generate_report"
    """
    # L√≥gica del reporte
    return f"Reporte generado: {start_date} - {end_date}"
```

### Paso 2: Registrar en module.py

```python
# modules/accounting/module.py

@property
def service(self) -> Dict[str, object]:
    from .adapter.input.tasks import accounting

    return {
        "accounting_service": self._container.accounting_service,
        "accounting_tasks": {
            "generate_report": accounting.generate_report,
        },
    }
```

### Paso 3: (Opcional) Crear Protocol

```python
# shared/interfaces/service_protocols.py

class AccountingTasksProtocol(Protocol):
    """API p√∫blica de tasks del m√≥dulo Accounting"""

    def generate_report(self, start_date: str, end_date: str) -> str:
        """Task para generar reporte contable"""
        ...
```

### Paso 4: Reiniciar el worker

```bash
# El worker detectar√° autom√°ticamente la nueva task
uv run hexa celery-apps
```

**Output:**
```
üì¶ Discovered 4 task services from service_locator
  ‚úì Registered: invoicing.emit_invoice
  ‚úì Registered: yiqi_erp.emit_invoice
  ‚úì Registered: notifications.send_notification
  ‚úì Registered: accounting.generate_report

‚úÖ Total 4 tasks registered in Celery worker
```

### Paso 5: Usar la task

```python
from shared.interfaces.service_locator import service_locator

tasks = service_locator.get_service("accounting_tasks")
tasks["generate_report"].delay("2025-01-01", "2025-01-31")
```

---

## Comparaci√≥n con Sistema Anterior

| Aspecto | Antes (Complejo) | Ahora (Simplificado) |
|---------|------------------|----------------------|
| **Instancias Celery** | Una por m√≥dulo | Una global |
| **Definici√≥n de tasks** | `@app.task` decorator | Funciones normales |
| **Discovery** | Escanea archivos buscando instancias | Lee desde service_locator |
| **Registro** | Merge manual de instancias | Autom√°tico con `app.task()` |
| **Testing** | Dif√≠cil (decoradores) | F√°cil (funciones puras) |
| **Type safety** | No | S√≠ (con Protocols) |
| **Configuraci√≥n** | Duplicada en cada m√≥dulo | Centralizada |
| **L√≠neas de c√≥digo** | ~100 l√≠neas | ~30 l√≠neas |

---

## Ventajas del Nuevo Sistema

1. **Simplicidad:** Tasks son funciones Python normales
2. **Consistencia:** Usa el mismo patr√≥n que otros servicios (service_locator)
3. **Type Safety:** Protocols permiten autocompletado y type checking
4. **Testing:** Funciones puras sin decoradores m√°gicos
5. **Mantenimiento:** Menos c√≥digo, m√°s f√°cil de entender
6. **Escalabilidad:** Agregar nuevas tasks es trivial
7. **Arquitectura Hexagonal:** Tasks como input adapters, consistente con el dise√±o

---

## Troubleshooting

### Task no se registra

**Problema:** La task no aparece en el worker

**Soluci√≥n:**
1. Verifica que el servicio termine en `_tasks`
2. Verifica que est√© en `module.py` dentro de `service`
3. Reinicia el worker: `uv run hexa celery-apps`

### Task no se ejecuta

**Problema:** `.delay()` no hace nada

**Soluci√≥n:**
1. Verifica que el worker est√© corriendo
2. Verifica que RabbitMQ est√© corriendo: `docker ps`
3. Revisa logs del worker para errores

### Type hints no funcionan

**Problema:** No hay autocompletado

**Soluci√≥n:**
1. Verifica que el Protocol exista en `service_protocols.py`
2. Usa type hints: `tasks: InvoicingTasksProtocol = service_locator.get_service(...)`
3. Reinicia el LSP de tu editor

---

## Archivos Modificados

- **[core/celery/discovery.py](backend/core/celery/discovery.py)** - Sistema de discovery simplificado
- **[hexa/__main__.py](backend/hexa/__main__.py)** - Comando para iniciar worker
- **[shared/interfaces/service_protocols.py](backend/shared/interfaces/service_protocols.py)** - Protocols para type safety
- **[modules/invoicing/module.py](backend/modules/invoicing/module.py)** - Registro de tasks
- **[modules/invoicing/adapter/input/tasks/invoice.py](backend/modules/invoicing/adapter/input/tasks/invoice.py)** - Task como funci√≥n normal
- **[modules/yiqi_erp/adapter/input/tasks/yiqi_erp.py](backend/modules/yiqi_erp/adapter/input/tasks/yiqi_erp.py)** - Task refactorizada
- **[modules/notifications/module.py](backend/modules/notifications/module.py)** - Nuevo m√≥dulo
- **[modules/notifications/adapter/input/tasks/notification.py](backend/modules/notifications/adapter/input/tasks/notification.py)** - Task refactorizada

---

**Fecha:** 2025-10-23
**Sistema:** Celery Tasks Simplificado con service_locator